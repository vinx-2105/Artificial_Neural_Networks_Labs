{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_lab2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJeUi3wOGNjN"
      },
      "source": [
        "# Lab 2 : Working with Recurrent Neural Networks\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Total Points: **100**\n",
        "\n",
        "Tentative Weightage : **10%**\n",
        "\n",
        "Submission Deadline :  **31st October 2020, 23:59 hours**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "General Instructions:\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "1. You have to do this lab individually\n",
        "2. You may use either **Tensorflow 2.x or PyTorch** framework\n",
        "3. Please start early as the experiments may take time to run\n",
        "4. All the code should be submitted in the form of a single Jupyter notebook itself.\n",
        "5. Points for each sub-section are mentioned in the appropriate question.\n",
        "6. You can use Google colab to run a jupyter notebook (https://colab.research.google.com/) How to load data in Google Colab ?(https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92) (https://www.marktechpost.com/2019/06/07/how-to-connect-google-colab-with-google-drive/)\n",
        "7. The lab must be submitted on Google classroom. The code as well as the accompanying observations should be made part of the python notebook.\n",
        "8. **Code Readability** is very important. Modularize your code by making use of classes, functions that can be flexibly reused wherever necessary. Also use self explanatory variable names and add comments to describe your approach wherever necessary. You may add additional code or text blocks as necessary.\n",
        "9. You are expected to submit your **detailed inferences** (preferably in a text block) and not just an error free code.\n",
        "10. Students are expected to follow the **honor code** of the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUMC6DqRuHYx"
      },
      "source": [
        "# #mount gdrive\n",
        "# from google.colab import drive\n",
        "# drive.mount('/gdrive')"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WyODX1hei-wD"
      },
      "source": [
        "# Import the necessary libraries\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTbExd28jAil"
      },
      "source": [
        "# Basic Linear Recurrent Neural Network from Scratch (Total for this subsection: **30 points**)\n",
        "---\n",
        "This section aims to design a simple one hidden layer RNN from scratch to count the number of ones in a binary sequence ( e.g., number of ones in  [ 1, 1, 1, 0, 0, 1, 0, 0, 1, 1] is 6) \n",
        "\n",
        "*   The structure of RNN and corresponding equations are given as follows:\n",
        "\n",
        "\n",
        "![rnn_structure.jpg](data:image/jpeg;base64,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)\n",
        "\n",
        "\n",
        "*   Since the update equations have been worked out, we are ready to implement.\n",
        "---\n",
        "Note 1: There are no non-linear activation functions in this architecture to make backpropagation of gradients simple.\n",
        "\n",
        "Note 2: The last timestamp's hidden state is the output of the network.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3dEZrTkvCPP"
      },
      "source": [
        "# Synthetic Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwMsksNWvMpA"
      },
      "source": [
        "# Following code snippet generates a binary sequence.  \n",
        "num_samples = 20\n",
        "sequence_len = 10\n",
        "# Sequences\n",
        "X = np.zeros((num_samples, sequence_len))\n",
        "for row_idx in range(num_samples):\n",
        "    X[row_idx,:] = np.around(np.random.rand(sequence_len)).astype(int)\n",
        "# print(X)\n",
        "# Targets\n",
        "t = np.sum(X, axis=1)\n",
        "# print(t)"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQnKWwnqvk1H"
      },
      "source": [
        "# To do:\n",
        "---\n",
        "* Perform forward and backward pass. You **cannot** use gradient tape in TensorFlow (or equivalent in PyTorch). **(4+6 = 10 points)**\n",
        "* Use mean square error for computing loss and plot the mesh-grid of the loss surface (w_x vs. w_rec). **(3 points)**\n",
        "* On this loss surface, mark points (w_x, w_rec) that show exploding and vanishing gradients property. **(2 points)**\n",
        "*  Give an insight into the instability of gradients during backward propagation on a graph. Plot a graph between gradients of loss w.r.t hidden state at time t (Y-axis) and timestamps t (X-axis). Note that you have to plot for various (w_x, w_rec) showing peculiar properties from the previous question. Mark your observations.  **(5 + 3 = 8 points)**\n",
        "* Use Rprop (Resilient Propagation) as an optimization algorithm; you can use the library (if any) for this part. **(3 points)**\n",
        "* Plot the optimization trajectory on the loss surface. **(2 points)**\n",
        "* Is your RNN well trained? Does it count the number of ones in the binary list well? How significant a change is observed in model training by introduction of Resilient Propoagation? **(2 points)**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7iwP-fTwqBA5"
      },
      "source": [
        "#  Hyperparameters\n",
        "**Initialization** \n",
        "* w_x   = -1.5\n",
        "* w_rec = 2\n",
        "* h_0   = 0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3exOkQMGFyYe"
      },
      "source": [
        "#initialise the paramters of the network\n",
        "w_x = -.15\n",
        "w_rec = 0.2\n",
        "h_0 = 0\n",
        "alpha = 0.001"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-ChtEAKY-N8"
      },
      "source": [
        "#y is the actual output\n",
        "def get_loss(y, y_label):\n",
        "  return (y-y_label)**2\n",
        "\n",
        "#y is the actual output\n",
        "def get_dl_dy(y, y_label):\n",
        "  return 2*(y-y_label)\n",
        "\n",
        "#get gradient of loss wrt previous timestep given the gradient wrt current timestep \n",
        "def get_dl_dht_minus_one(dl_dht):\n",
        "  return dl_dht*w_rec\n",
        "\n",
        "#get h_t from ht-1 and x_t\n",
        "def get_ht(ht_minus_one, x_t):\n",
        "  return ht_minus_one*w_rec + x_t*w_x\n",
        "\n",
        "def get_dl_dw_x(dl_dht, x_t):\n",
        "  #index of t[1...n]\n",
        "  return np.sum(np.multiply(dl_dht, x_t))\n",
        "\n",
        "def get_dl_dw_rec(dl_dht, ht_minus_1):\n",
        "  #index of t[1...n]\n",
        "  return np.sum(np.multiply(dl_dht, ht_minus_1))\n"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOmYCXhj030V"
      },
      "source": [
        "#number of timesteps in input\n",
        "T = X.shape[1]\n",
        "h_t_mat = np.zeros(T+1)\n",
        "dl_dht_mat = np.zeros(T+1)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TuCPrws1isvo",
        "outputId": "53ac14ae-9a94-492d-de29-40e94a2be980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "for x in X:\n",
        "  y_label = np.sum(x)\n",
        "  #do a forward pass through the network\n",
        "  for t in range(1, T+1):\n",
        "    h_t_mat[t] = get_ht(h_t_mat[t-1], x[t-1])#x_t is stored at x[t-1] since t starts from 1 \n",
        "    # print(h_t_mat[t])\n",
        "    # print(t, h_t_mat[t])\n",
        "  y = h_t_mat[T]\n",
        "  # print(y, y_label)\n",
        "  #do the backward pass now for this x\n",
        "  loss = get_loss(y, y_label)\n",
        "\n",
        "  #compute the gradients\n",
        "  dl_dht_mat[T] = get_dl_dy(y, y_label)\n",
        "  for t in range(0, T):\n",
        "    dl_dht_mat[t] = get_dl_dht_minus_one(dl_dht=dl_dht_mat[t+1])\n",
        "\n",
        "  dl_dw_x = get_dl_dw_x(dl_dht_mat[1:], x)\n",
        "  dl_dw_rec = get_dl_dw_rec(dl_dht_mat[1:], h_t_mat[:-1])\n",
        "\n",
        "  print(dl_dw_x, dl_dw_rec)                                                                                                              \n",
        "  # update the paramters\n",
        "  w_x = w_x - alpha*dl_dw_x\n",
        "  w_rec = w_rec - alpha*dl_dw_rec \n",
        "  # break"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-2.01257987072 1.6553144203764891\n",
            "-6.298285041418073 0.13245110731658805\n",
            "-10.074319138580547 1.3101773254988918\n",
            "-17.200943106109705 2.117492132091633\n",
            "-6.293946474135828 0.11861893364971501\n",
            "-0.012935507576050356 0.02756339869918779\n",
            "-8.240165085954521 0.031115655585966767\n",
            "-12.57395604236665 0.6281090660661554\n",
            "-12.188789886612861 0.8915257158040034\n",
            "-17.39823948280707 1.5915659187897786\n",
            "-0.6148581007994957 0.25777477373979396\n",
            "-2.3110000797393018 0.8500452301741855\n",
            "-2.732834145221732 0.9983375835426519\n",
            "-12.045315878202539 0.5311541377058833\n",
            "-2.2692614465316048 0.5663345033418961\n",
            "-8.159684046181312 0.044248671896050605\n",
            "-17.024069741304793 0.5845775333354798\n",
            "-2.765174358921376 0.21192721077277346\n",
            "-14.455616019814704 0.05587900606953582\n",
            "-0.5104898480452766 -0.015384980528398587\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGJiDp4iIBQF"
      },
      "source": [
        "# Machine Translation\n",
        "\n",
        "---\n",
        "In this section we will use the modified RNN's (LSTM or GRU) which can overcome the shortcomings of the multi layer Vanilla RNN for the Machine Translation task. We will be using the Hindi - English sentence pairs dataset for this exercise. The dataset can be downloaded from [Kaggle link](https://www.kaggle.com/kkhandekar/hindi-english-sentence-pairs) \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AS28Yk6nlRHV"
      },
      "source": [
        "# To do\n",
        "\n",
        "---\n",
        "## Data Preprocessing (Total for this subsection : 10 points)\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "1. For ease of implementation, convert all English characters to either lower case or upper case **(1 point)**\n",
        "2. Replace punctuations by spaces **(1 point)**\n",
        "3. Add \\<start\\> token to the begin of each sentence (both English and Hindi) **(1 point)**\n",
        "4. Add \\<end\\> token to the end of each sentence (both English and Hindi) **(1 point)**\n",
        "5. Use a built in library tokenizer to convert words to tokens (numeric representation) (both English and Hindi) **(2 points)**\n",
        "6. Use \\<pad\\> token so that all statements of a language has same length **(1 point)**\n",
        "7. Convert a random instance from token sequence into words and display the human readable words (both English and Hindi) **(2 points)**\n",
        "8. Split the dataset in 80%/20% split to get train and test sets **(1 point)**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cNa17d2lVsY"
      },
      "source": [
        "## Model Architecture\n",
        "\n",
        "---\n",
        "\n",
        "In general machine translation systems use two RNN's commonly called as Encoder and Decoder. Encoder works on the input language sequence and converts it into a hidden representation on which decoder works. Decoder is responsible for generating the target language sequence. Attention mechanism is used to learn which parts of the input sequence is to be looked at in order to generate the translation in the target language. \n",
        "\n",
        "**Note:** You may use LSTM or GRU or any special layers of your choice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12YUvt4goGdb"
      },
      "source": [
        "## Translator Model (Total for this subsection : 60 points)\n",
        "\n",
        "---\n",
        "\n",
        "1. We will be doing a English to Hindi translation task\n",
        "2. Design a suitable encoder architecture to process the input sequences in English **(15 points)**\n",
        "3. Use the attention Mechanism by Bahdanau et al. [1] to learn the effective alignment between English and Hindi sequences **(15 points)**\n",
        "4. Design a suitable decoder architecture which can generate the target Hindi sequence based on the soft aligned English sequence **(15 points)**\n",
        "5. Train the encoder-decoder sequence based on the cross entropy loss **(10 points)**\n",
        "6. Use the BLEU score metric (pre defined library implementations in Python may be used) and discuss the goodness of the learned translator model **(5 points)**\n",
        "\n",
        "\n",
        "### Reference:\n",
        "[1] Dzmitry Bahdanau, KyungHyun Cho, Yoshua Bengio , \"Neural Machine Translation\n",
        "By Jointly Learning To Align And Translate\", ICLR 2015\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlqCDIOSp8SL"
      },
      "source": [
        "#Data preprocessing\n",
        "BASE_PATH = '/gdrive/My Drive/ANN/lab_2/'\n",
        "DATA_PATH = BASE_PATH + 'training_data/hin.txt'"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ7R7Q21ls82"
      },
      "source": [
        "PAD_TOKEN = \" \\<pad>\""
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP5H0XvFuCKD"
      },
      "source": [
        "ENGLISH_DATA =[]\n",
        "HINDI_DATA = []\n",
        "\n",
        "MAX_LENGTH = 0\n",
        "\n",
        "with open(DATA_PATH, 'r') as f:\n",
        "  lines = f.readlines()\n",
        "  for line in lines:\n",
        "    split_line = line.split(sep='\\t')\n",
        "    english_line = split_line[0].lower() #convert all english letters to lower case\n",
        "    english_line = english_line.replace('\\\"', '')\n",
        "    english_line = english_line.replace(',', '')\n",
        "    english_line = english_line.replace('.', '')\n",
        "    english_line = english_line.replace('?', '')\n",
        "    english_line.strip()\n",
        "    english_line = re.sub('\\s+', ' ', english_line) \n",
        "\n",
        "    if english_line=='Do you like this book':\n",
        "      print(english_line)\n",
        "\n",
        "    english_line = \"\\<start> \" + english_line + \" \\<end>\"\n",
        "\n",
        "    hindi_line = split_line[1]\n",
        "    hindi_line = hindi_line.replace('\\\"', '')\n",
        "    hindi_line = hindi_line.replace(',', '')\n",
        "    hindi_line = hindi_line.replace('.', '')\n",
        "    hindi_line = hindi_line.replace('?', '')\n",
        "    hindi_line.strip()\n",
        "    hindi_line = re.sub('\\s+', ' ', hindi_line) \n",
        "\n",
        "    hindi_line = \"\\<start> \" + hindi_line + \" \\<end>\"\n",
        "\n",
        "    ENGLISH_DATA.append(english_line)\n",
        "    HINDI_DATA.append(hindi_line)\n",
        "\n",
        "    MAX_LENGTH = max(MAX_LENGTH, max(len(english_line.split(sep=' ')), len(hindi_line.split(sep=' '))))\n",
        "    # MAX_LENGTH = max(MAX_LENGTH, len(english_line.split(sep=' ')))\n",
        "\n",
        "    \n",
        "#pad each line with so that every line is equal to MAX_LENGTH\n",
        "for i in range(len(ENGLISH_DATA)):\n",
        "  line = ENGLISH_DATA[i]\n",
        "  num_pads = MAX_LENGTH-len(line.split(sep=' '))\n",
        "  ENGLISH_DATA[i] = line + PAD_TOKEN*num_pads\n",
        "\n",
        "for i in range(len(HINDI_DATA)):\n",
        "  line = HINDI_DATA[i]\n",
        "  line = re.sub('\\s+', ' ', line)\n",
        "  num_pads = MAX_LENGTH-len(line.split(sep=' '))\n",
        "  HINDI_DATA[i] = line + PAD_TOKEN*num_pads"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9S-fknyEEzE5",
        "outputId": "98b5a638-6eaf-49b2-ee3f-2c6c0aa529ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(MAX_LENGTH)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g2Zpy-7yuER_"
      },
      "source": [
        "#define an instance of the tokenizer class for english\n",
        "english_tokenizer = tf.keras.preprocessing.text.Tokenizer(split=' ', filters='')\n",
        "english_tokenizer.fit_on_texts(ENGLISH_DATA)\n",
        "english_tokens = english_tokenizer.texts_to_sequences(ENGLISH_DATA)\n",
        "english_tokens = np.array(english_tokens)\n",
        "\n",
        "#define an instance of the tokenizer class for hindi\n",
        "hindi_tokenizer = tf.keras.preprocessing.text.Tokenizer(split=' ', filters='')\n",
        "hindi_tokenizer.fit_on_texts(HINDI_DATA)\n",
        "hindi_tokens = hindi_tokenizer.texts_to_sequences(HINDI_DATA)\n",
        "hindi_tokens = np.array(hindi_tokens)\n"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2TTeSm6LNW97",
        "outputId": "bc261127-7755-473e-fde8-51d5793b14d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "source": [
        " #convert a random instance from token sequence into words and display the human readable words\n",
        "print(english_tokenizer.sequences_to_texts([english_tokens[1000]]))\n",
        "print(hindi_tokenizer.sequences_to_texts([hindi_tokens[1000]]))"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['\\\\<start> he wanted to buy the book \\\\<end> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad>']\n",
            "['\\\\<start>       \\\\<end> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad> \\\\<pad>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zFgR7ClqgKI"
      },
      "source": [
        "def split_dataset(english_tokens, hindi_tokens, train_percent=80):\n",
        "  data_length = len(english_tokens)\n",
        "  train_length = int(data_length*(train_percent/100.0))\n",
        "\n",
        "  training_indices = random.sample([i for i in range(data_length)], train_length)\n",
        "\n",
        "  test_indices = [i for i in range(data_length)]\n",
        "\n",
        "  for i in training_indices:\n",
        "    test_indices.remove(i)\n",
        "\n",
        "  eng_train_dataset = []\n",
        "  eng_test_dataset = []\n",
        "  hin_train_dataset = []\n",
        "  hin_test_dataset = []\n",
        "\n",
        "  for idx in training_indices:\n",
        "    eng_train_dataset.append(english_tokens[idx])\n",
        "    hin_train_dataset.append(hindi_tokens[idx])\n",
        "  \n",
        "  for idx in test_indices:\n",
        "    eng_test_dataset.append(english_tokens[idx])\n",
        "    hin_test_dataset.append(hindi_tokens[idx])\n",
        "\n",
        "  return np.array(eng_train_dataset), np.array(eng_test_dataset), np.array(hin_train_dataset), np.array(hin_test_dataset) \n"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yzq9SfLsteGv",
        "outputId": "70485f18-13ab-447f-eb58-812bcca166af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "english_train_dataset, english_test_dataset, hindi_train_dataset, hindi_test_dataset = split_dataset(english_tokens, hindi_tokens, train_percent=80)\n",
        "print(english_train_dataset.shape, english_test_dataset.shape, hindi_train_dataset.shape, hindi_test_dataset.shape)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2219, 27) (555, 27) (2219, 27) (555, 27)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VcOmJpQiDWL"
      },
      "source": [
        "####Create the TF dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poEAdeFYmwsX"
      },
      "source": [
        "BUFFER_SIZE = len(english_train_dataset)\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "steps_per_epoch = len(english_train_dataset)//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "\n",
        "vocab_input_size = len(english_tokenizer.word_index)+1\n",
        "vocab_output_size = len(hindi_tokenizer.word_index)+1\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((english_train_dataset, hindi_train_dataset)).shuffle(BUFFER_SIZE)\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((english_test_dataset, hindi_test_dataset)).shuffle(BUFFER_SIZE)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPvOfg3UXDAz",
        "outputId": "887c29ca-5d25-4b6b-f260-4c725f4cd82a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188
        }
      },
      "source": [
        "example_input_batch, example_target_batch = next(iter(train_dataset))\n",
        "example_input_batch.shape, example_target_batch.shape"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-137-abc03384a8f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexample_input_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_target_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mexample_input_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_target_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNNSUbNzu5V5"
      },
      "source": [
        "####Define the Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cDE-VwXnigLx"
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, emb_dim, enc_units, batch_size):\n",
        "    super(Encoder, self).__init__()#call the constructor of the parent class\n",
        "    self.vocab_size = vocab_size #size of the embedding\n",
        "    self.emb_dim = emb_dim #size of the embedding \n",
        "    self.enc_units = enc_units #size of the LSTM layer\n",
        "    self.batch_size = batch_size #batch size of the dataset\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.emb_dim)\n",
        "    #return sequences is true because we will need the hidden state for each time step and not just the final one\n",
        "    #return state is true which provides access to the cell state and the hidden state\n",
        "    self.gru = tf.keras.layers.GRU(self.enc_units, return_sequences=True, return_state=True)\n",
        "\n",
        "  def call(self, x, hidden):\n",
        "    x = self.embedding(x)\n",
        "    output, state = self.gru(x, initial_state=hidden)\n",
        "    return output, state\n",
        "\n",
        "  def initialize_hidden_state(self):\n",
        "    return tf.zeros((self.batch_size, self.enc_units))"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDvA0X7K3eeB",
        "outputId": "0715cb25-adab-4a3b-97c7-82f0c81e51e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "encoder = Encoder(vocab_input_size, embedding_dim, units, BATCH_SIZE)\n",
        "\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 27, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3M39RoN35YX"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\n",
        "  def __init__(self, units):\n",
        "    super(BahdanauAttention, self).__init__()\n",
        "    self.eo_w = tf.keras.layers.Dense(units)\n",
        "    self.ehs_w = tf.keras.layers.Dense(units)\n",
        "    self.score_w = tf.keras.layers.Dense(1)\n",
        "\n",
        "  def call(self, encoder_hidden_state, encoder_output):\n",
        "    #encoder_hidden_state has shape (batch_size, hidden_size)\n",
        "    #encoder_output has shape (batch_size, max_length, hidden_size)\n",
        "    encoder_hidden_state = tf.expand_dims(encoder_hidden_state, axis=1)\n",
        "    #encoder_hidden_state has shape (batch_size, 1, hidden_size)\n",
        "\n",
        "    #now calculate the score\n",
        "    attention_score = self.score_w(tf.nn.tanh(self.eo_w(encoder_output) + self.ehs_w(encoder_hidden_state)))\n",
        "    #normalize using softmax\n",
        "    attention_score = tf.nn.softmax(attention_score, axis=1)#attention score has shape (batch_size, max_length, 1)\n",
        "    #calculate context vector\n",
        "    context_vec =  attention_score*encoder_output #context vector has size (batch_size, max_length, hidden_size)\n",
        "    context_vec = tf.reduce_sum(context_vec, axis=1) #context vector has size (batch_size, hidden_size)\n",
        "\n",
        "    #context vector has size (batch_size, hidden_size); attention score has shape (batch_size, max_length, 1);\n",
        "    return context_vec, attention_score\n"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KG5xugk-TbO5"
      },
      "source": [
        "####Define the decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qs4b36vN7txh"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, emb_dim, dec_units, batch_size):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.vocab_size = vocab_size\n",
        "    self.emb_dim = emb_dim\n",
        "    self.dec_units = dec_units\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    self.embedding = tf.keras.layers.Embedding(self.vocab_size, self.emb_dim)\n",
        "    self.gru = tf.keras.layers.GRU(self.dec_units, return_sequences=True, return_state=True)\n",
        "    self.fc = tf.keras.layers.Dense(vocab_size)\n",
        "    self.attention = BahdanauAttention(self.dec_units)\n",
        "\n",
        "  def call(self, x, hidden, enc_output):\n",
        "    #get the context vector and attention weights\n",
        "    context_vector, attention_weights = self.attention(hidden, enc_output)\n",
        "    # print(\"context1-->{}; x-->{}\".format(context_vector.shape, x.shape))\n",
        "\n",
        "    # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
        "    x = self.embedding(x)\n",
        "\n",
        "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
        "    # print(\"context2-->{}; x-->{}\".format(context_vector.shape, x.shape))\n",
        "    x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "\n",
        "    # passing the concatenated vector to the GRU\n",
        "    output, state = self.gru(x)\n",
        "\n",
        "    # output shape == (batch_size * 1, hidden_size)\n",
        "    output = tf.reshape(output, (-1, output.shape[2]))\n",
        "\n",
        "    # output shape == (batch_size, vocab)\n",
        "    x = self.fc(output)\n",
        "\n",
        "    return x, state, attention_weights\n"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQVS6jNtTLTQ",
        "outputId": "4658450f-7f64-490c-f804-71e4fcbbcccd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "decoder = Decoder(vocab_output_size, embedding_dim, units, BATCH_SIZE)\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)), sample_hidden, sample_output)\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 3009)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5NiCo1G1TWb5"
      },
      "source": [
        "####Define optimizer and loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bK-Z6xYkThcn"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "  mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "  loss_ = loss_object(real, pred)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "julMywR8Tyw8"
      },
      "source": [
        "####Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsHQQA1KTrNV",
        "outputId": "c0877553-fd8e-466f-f098-6078ecf95410",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#do the training\n",
        "EPOCHS = 5\n",
        "\n",
        "for epoch in tqdm(range(EPOCHS)):\n",
        "  #initilise the h_0 state of the encoder\n",
        "  enc_hidden_state = encoder.initialize_hidden_state()\n",
        "\n",
        "  #iterate thru the training batches\n",
        "  for iter, (english_train_batch, hindi_train_batch) in enumerate(train_dataset, 0):\n",
        "    #define the gradient tape\n",
        "    loss = 0.0\n",
        "    with tf.GradientTape() as tape:\n",
        "      #pass through the encoder\n",
        "      enc_output, enc_hidden_state = encoder(english_train_batch, enc_hidden_state)\n",
        "\n",
        "      #now do a forward pass thru the decoder\n",
        "      #initialize the dec_hidden_state with the hidden state of the encoder\n",
        "      dec_hidden_state = enc_hidden_state\n",
        "      dec_input = tf.expand_dims([hindi_tokenizer.word_index['\\<start>']]*BATCH_SIZE, axis=1)\n",
        "\n",
        "      for timestep in range(1, hindi_train_batch.shape[1]):\n",
        "        pred, dec_hidden, attention_weights = decoder(dec_input, dec_hidden_state, enc_output)\n",
        "        loss += loss_function(hindi_train_batch[:, timestep], pred)\n",
        "\n",
        "        #set the next decoder input\n",
        "        dec_input = tf.expand_dims(hindi_train_batch[:, timestep] , axis=1)\n",
        "\n",
        "      avg_loss = loss/hindi_train_batch.shape[1]\n",
        "\n",
        "      trainable_vars = encoder.trainable_variables + decoder.trainable_variables\n",
        "\n",
        "      grads = tape.gradient(loss, trainable_vars)\n",
        "\n",
        "      optimizer.apply_gradients(zip(grads, trainable_vars))\n",
        "\n",
        "    print(\"Epoch-->{}; Iteration-->{}; Loss-->{};\".format(epoch, iter, avg_loss.numpy()))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch-->0; Iteration-->0; Loss-->7.574917316436768;\n",
            "Epoch-->0; Iteration-->1; Loss-->7.231700420379639;\n",
            "Epoch-->0; Iteration-->2; Loss-->5.243013381958008;\n",
            "Epoch-->0; Iteration-->3; Loss-->4.643458366394043;\n",
            "Epoch-->0; Iteration-->4; Loss-->4.526457786560059;\n",
            "Epoch-->0; Iteration-->5; Loss-->3.631026029586792;\n",
            "Epoch-->0; Iteration-->6; Loss-->2.512852907180786;\n",
            "Epoch-->0; Iteration-->7; Loss-->2.9216787815093994;\n",
            "Epoch-->0; Iteration-->8; Loss-->3.050316095352173;\n",
            "Epoch-->0; Iteration-->9; Loss-->2.6867244243621826;\n",
            "Epoch-->0; Iteration-->10; Loss-->2.344456195831299;\n",
            "Epoch-->0; Iteration-->11; Loss-->2.401665687561035;\n",
            "Epoch-->0; Iteration-->12; Loss-->2.443804979324341;\n",
            "Epoch-->0; Iteration-->13; Loss-->2.497537612915039;\n",
            "Epoch-->0; Iteration-->14; Loss-->2.609511375427246;\n",
            "Epoch-->0; Iteration-->15; Loss-->2.677354335784912;\n",
            "Epoch-->0; Iteration-->16; Loss-->2.498575448989868;\n",
            "Epoch-->0; Iteration-->17; Loss-->2.564821481704712;\n",
            "Epoch-->0; Iteration-->18; Loss-->2.542412281036377;\n",
            "Epoch-->0; Iteration-->19; Loss-->2.35196852684021;\n",
            "Epoch-->0; Iteration-->20; Loss-->2.317962408065796;\n",
            "Epoch-->0; Iteration-->21; Loss-->2.502922296524048;\n",
            "Epoch-->0; Iteration-->22; Loss-->2.3366029262542725;\n",
            "Epoch-->0; Iteration-->23; Loss-->2.1857504844665527;\n",
            "Epoch-->0; Iteration-->24; Loss-->2.371722936630249;\n",
            "Epoch-->0; Iteration-->25; Loss-->2.26666522026062;\n",
            "Epoch-->0; Iteration-->26; Loss-->2.1715965270996094;\n",
            "Epoch-->0; Iteration-->27; Loss-->2.2652077674865723;\n",
            "Epoch-->0; Iteration-->28; Loss-->2.453504800796509;\n",
            "Epoch-->0; Iteration-->29; Loss-->2.2882328033447266;\n",
            "Epoch-->0; Iteration-->30; Loss-->2.2261850833892822;\n",
            "Epoch-->0; Iteration-->31; Loss-->2.3044686317443848;\n",
            "Epoch-->0; Iteration-->32; Loss-->2.314382314682007;\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 10%|         | 1/10 [06:34<59:10, 394.47s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch-->0; Iteration-->33; Loss-->2.297211170196533;\n",
            "Epoch-->1; Iteration-->0; Loss-->2.1648647785186768;\n",
            "Epoch-->1; Iteration-->1; Loss-->2.3328802585601807;\n",
            "Epoch-->1; Iteration-->2; Loss-->2.0483779907226562;\n",
            "Epoch-->1; Iteration-->3; Loss-->2.129817008972168;\n",
            "Epoch-->1; Iteration-->4; Loss-->2.117133140563965;\n",
            "Epoch-->1; Iteration-->5; Loss-->2.0788722038269043;\n",
            "Epoch-->1; Iteration-->6; Loss-->2.147226572036743;\n",
            "Epoch-->1; Iteration-->7; Loss-->2.2918543815612793;\n",
            "Epoch-->1; Iteration-->8; Loss-->2.0309088230133057;\n",
            "Epoch-->1; Iteration-->9; Loss-->2.0824198722839355;\n",
            "Epoch-->1; Iteration-->10; Loss-->1.9022979736328125;\n",
            "Epoch-->1; Iteration-->11; Loss-->2.07271146774292;\n",
            "Epoch-->1; Iteration-->12; Loss-->2.0683529376983643;\n",
            "Epoch-->1; Iteration-->13; Loss-->1.9908801317214966;\n",
            "Epoch-->1; Iteration-->14; Loss-->1.825421929359436;\n",
            "Epoch-->1; Iteration-->15; Loss-->1.8651833534240723;\n",
            "Epoch-->1; Iteration-->16; Loss-->1.9781607389450073;\n",
            "Epoch-->1; Iteration-->17; Loss-->1.7665138244628906;\n",
            "Epoch-->1; Iteration-->18; Loss-->1.7535102367401123;\n",
            "Epoch-->1; Iteration-->19; Loss-->1.9888005256652832;\n",
            "Epoch-->1; Iteration-->20; Loss-->1.872408151626587;\n",
            "Epoch-->1; Iteration-->21; Loss-->1.7914953231811523;\n",
            "Epoch-->1; Iteration-->22; Loss-->1.7737268209457397;\n",
            "Epoch-->1; Iteration-->23; Loss-->1.8072069883346558;\n",
            "Epoch-->1; Iteration-->24; Loss-->1.8301554918289185;\n",
            "Epoch-->1; Iteration-->25; Loss-->1.674178123474121;\n",
            "Epoch-->1; Iteration-->26; Loss-->1.882488489151001;\n",
            "Epoch-->1; Iteration-->27; Loss-->1.8025251626968384;\n",
            "Epoch-->1; Iteration-->28; Loss-->1.8202574253082275;\n",
            "Epoch-->1; Iteration-->29; Loss-->1.8815217018127441;\n",
            "Epoch-->1; Iteration-->30; Loss-->1.7982674837112427;\n",
            "Epoch-->1; Iteration-->31; Loss-->1.8698092699050903;\n",
            "Epoch-->1; Iteration-->32; Loss-->1.785002589225769;\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 20%|        | 2/10 [13:08<52:34, 394.26s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch-->1; Iteration-->33; Loss-->1.865809440612793;\n",
            "Epoch-->2; Iteration-->0; Loss-->1.6750249862670898;\n",
            "Epoch-->2; Iteration-->1; Loss-->1.7876592874526978;\n",
            "Epoch-->2; Iteration-->2; Loss-->1.6908005475997925;\n",
            "Epoch-->2; Iteration-->3; Loss-->1.9405614137649536;\n",
            "Epoch-->2; Iteration-->4; Loss-->1.7710511684417725;\n",
            "Epoch-->2; Iteration-->5; Loss-->1.751384973526001;\n",
            "Epoch-->2; Iteration-->6; Loss-->1.88821280002594;\n",
            "Epoch-->2; Iteration-->7; Loss-->1.818217158317566;\n",
            "Epoch-->2; Iteration-->8; Loss-->1.617590308189392;\n",
            "Epoch-->2; Iteration-->9; Loss-->1.6818506717681885;\n",
            "Epoch-->2; Iteration-->10; Loss-->1.7279839515686035;\n",
            "Epoch-->2; Iteration-->11; Loss-->1.8632851839065552;\n",
            "Epoch-->2; Iteration-->12; Loss-->1.7183830738067627;\n",
            "Epoch-->2; Iteration-->13; Loss-->1.6806650161743164;\n",
            "Epoch-->2; Iteration-->14; Loss-->1.9317855834960938;\n",
            "Epoch-->2; Iteration-->15; Loss-->1.7932660579681396;\n",
            "Epoch-->2; Iteration-->16; Loss-->1.6962846517562866;\n",
            "Epoch-->2; Iteration-->17; Loss-->1.7032098770141602;\n",
            "Epoch-->2; Iteration-->18; Loss-->1.5966252088546753;\n",
            "Epoch-->2; Iteration-->19; Loss-->1.6333770751953125;\n",
            "Epoch-->2; Iteration-->20; Loss-->1.9258649349212646;\n",
            "Epoch-->2; Iteration-->21; Loss-->1.7092498540878296;\n",
            "Epoch-->2; Iteration-->22; Loss-->1.7249512672424316;\n",
            "Epoch-->2; Iteration-->23; Loss-->1.7096205949783325;\n",
            "Epoch-->2; Iteration-->24; Loss-->1.6616333723068237;\n",
            "Epoch-->2; Iteration-->25; Loss-->1.7500442266464233;\n",
            "Epoch-->2; Iteration-->26; Loss-->1.7277296781539917;\n",
            "Epoch-->2; Iteration-->27; Loss-->1.7083165645599365;\n",
            "Epoch-->2; Iteration-->28; Loss-->1.6190942525863647;\n",
            "Epoch-->2; Iteration-->29; Loss-->1.6070466041564941;\n",
            "Epoch-->2; Iteration-->30; Loss-->1.8541935682296753;\n",
            "Epoch-->2; Iteration-->31; Loss-->1.9123039245605469;\n",
            "Epoch-->2; Iteration-->32; Loss-->1.8956135511398315;\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 30%|       | 3/10 [19:42<45:59, 394.16s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch-->2; Iteration-->33; Loss-->1.7508512735366821;\n",
            "Epoch-->3; Iteration-->0; Loss-->1.6673780679702759;\n",
            "Epoch-->3; Iteration-->1; Loss-->1.7574150562286377;\n",
            "Epoch-->3; Iteration-->2; Loss-->1.6814100742340088;\n",
            "Epoch-->3; Iteration-->3; Loss-->1.7368963956832886;\n",
            "Epoch-->3; Iteration-->4; Loss-->1.7271835803985596;\n",
            "Epoch-->3; Iteration-->5; Loss-->1.6250554323196411;\n",
            "Epoch-->3; Iteration-->6; Loss-->1.6485682725906372;\n",
            "Epoch-->3; Iteration-->7; Loss-->1.7654820680618286;\n",
            "Epoch-->3; Iteration-->8; Loss-->1.6582220792770386;\n",
            "Epoch-->3; Iteration-->9; Loss-->1.6784591674804688;\n",
            "Epoch-->3; Iteration-->10; Loss-->1.8004525899887085;\n",
            "Epoch-->3; Iteration-->11; Loss-->1.5961344242095947;\n",
            "Epoch-->3; Iteration-->12; Loss-->1.6746238470077515;\n",
            "Epoch-->3; Iteration-->13; Loss-->1.7021055221557617;\n",
            "Epoch-->3; Iteration-->14; Loss-->1.6541723012924194;\n",
            "Epoch-->3; Iteration-->15; Loss-->1.603464961051941;\n",
            "Epoch-->3; Iteration-->16; Loss-->1.721356749534607;\n",
            "Epoch-->3; Iteration-->17; Loss-->1.7075796127319336;\n",
            "Epoch-->3; Iteration-->18; Loss-->1.7441743612289429;\n",
            "Epoch-->3; Iteration-->19; Loss-->1.590668797492981;\n",
            "Epoch-->3; Iteration-->20; Loss-->1.6375291347503662;\n",
            "Epoch-->3; Iteration-->21; Loss-->1.677818775177002;\n",
            "Epoch-->3; Iteration-->22; Loss-->1.704826831817627;\n",
            "Epoch-->3; Iteration-->23; Loss-->1.7392868995666504;\n",
            "Epoch-->3; Iteration-->24; Loss-->1.6789480447769165;\n",
            "Epoch-->3; Iteration-->25; Loss-->1.6339212656021118;\n",
            "Epoch-->3; Iteration-->26; Loss-->1.555687665939331;\n",
            "Epoch-->3; Iteration-->27; Loss-->1.6323530673980713;\n",
            "Epoch-->3; Iteration-->28; Loss-->1.6805120706558228;\n",
            "Epoch-->3; Iteration-->29; Loss-->1.7901524305343628;\n",
            "Epoch-->3; Iteration-->30; Loss-->1.6356481313705444;\n",
            "Epoch-->3; Iteration-->31; Loss-->1.674071192741394;\n",
            "Epoch-->3; Iteration-->32; Loss-->1.6946637630462646;\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            " 40%|      | 4/10 [26:14<39:21, 393.64s/it]\u001b[A\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch-->3; Iteration-->33; Loss-->1.8109426498413086;\n",
            "Epoch-->4; Iteration-->0; Loss-->1.6069293022155762;\n",
            "Epoch-->4; Iteration-->1; Loss-->1.5795807838439941;\n",
            "Epoch-->4; Iteration-->2; Loss-->1.4940630197525024;\n",
            "Epoch-->4; Iteration-->3; Loss-->1.634912371635437;\n",
            "Epoch-->4; Iteration-->4; Loss-->1.7401193380355835;\n",
            "Epoch-->4; Iteration-->5; Loss-->1.5384206771850586;\n",
            "Epoch-->4; Iteration-->6; Loss-->1.7961479425430298;\n",
            "Epoch-->4; Iteration-->7; Loss-->1.6214762926101685;\n",
            "Epoch-->4; Iteration-->8; Loss-->1.7310869693756104;\n",
            "Epoch-->4; Iteration-->9; Loss-->1.7410898208618164;\n",
            "Epoch-->4; Iteration-->10; Loss-->1.5118567943572998;\n",
            "Epoch-->4; Iteration-->11; Loss-->1.67670738697052;\n",
            "Epoch-->4; Iteration-->12; Loss-->1.7264821529388428;\n",
            "Epoch-->4; Iteration-->13; Loss-->1.7085624933242798;\n",
            "Epoch-->4; Iteration-->14; Loss-->1.5591758489608765;\n",
            "Epoch-->4; Iteration-->15; Loss-->1.4758720397949219;\n",
            "Epoch-->4; Iteration-->16; Loss-->1.5123262405395508;\n",
            "Epoch-->4; Iteration-->17; Loss-->1.6416112184524536;\n",
            "Epoch-->4; Iteration-->18; Loss-->1.5643481016159058;\n",
            "Epoch-->4; Iteration-->19; Loss-->1.748591661453247;\n",
            "Epoch-->4; Iteration-->20; Loss-->1.7608542442321777;\n",
            "Epoch-->4; Iteration-->21; Loss-->1.560505986213684;\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSd0zvspQ4it"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}