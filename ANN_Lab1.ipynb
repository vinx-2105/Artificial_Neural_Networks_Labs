{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ANN_Lab1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hRmlvsGdvzI",
        "colab_type": "text"
      },
      "source": [
        "# Lab 1 : Working with Optimizers and Convolutional Neural Networks\n",
        "\n",
        "---\n",
        "\n",
        "Total Points: **60**\n",
        "\n",
        "Tentative Weightage : **10%**\n",
        "\n",
        "Submission Deadline : **11th September 2020, 23:59 hours**\n",
        "\n",
        "---\n",
        "**General Instructions:**\n",
        "\n",
        "---\n",
        "1. You have to do this lab individually\n",
        "2. You may use either Tensorflow 2.x or PyTorch framework\n",
        "3. Please start **early** as the experiments may take time to run\n",
        "4. All the code should be submitted in the form of a single Jupyter notebook itself.\n",
        "5. Points for each sub-section are mentioned in the appropriate question.\n",
        "6. You can use Google colab to run a jupyter notebook (https://colab.research.google.com/) How to load data in Google Colab ?(https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92) (https://www.marktechpost.com/2019/06/07/how-to-connect-google-colab-with-google-drive/)\n",
        "7. The lab must be submitted on **Google classroom**. The code as well as the accompanying observations should be made part of the python notebook.\n",
        "8. **Code Readability** is very important. Modularize your code by making use of classes, functions that can be flexibly reused wherever necessary. Also use self explanatory variable names and add comments to describe your approach wherever necessary. You may add additional code or text blocks as necessary. \n",
        "9.You are expected to submit your **detailed inferences** (preferably in a text block) and not just an error free code.\n",
        "10. Students are expected to follow the **honor code** of the class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oAnuY4nMdoOa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the necessary libraries "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sz48_f8mcFCi",
        "colab_type": "text"
      },
      "source": [
        "# Optimizers(Total for this subsection : **30 points**)\n",
        "---\n",
        "The aim of this section is to understand the loss surface of the neural network and study the behaviour of various optimization algorithms on it.\n",
        "\n",
        "## To do\n",
        "\n",
        "---\n",
        "1. Study and implement: \n",
        "  *   Mini-batch gradient descent       **{2 points}**\n",
        "  *   RMSProp [1]                       **{2 points}**\n",
        "  *   Nesterov Accelerated Gradient [2] **{2 points}**\n",
        "  *   ADAM [4]                          **{2 points}**\n",
        "\n",
        " on a two dimensional fuction like $f(w_1,w_2)=a_1(w_1-b_1)^2 +a_2(w_2-b_2)^2+c$ where $a_1,a_2,b_1,b_2$ and $c$ are hyperparameters which affect the rate of convergence of these algorithms.\n",
        "2. Experiment these optimization techniques on the non-convex function(s)  (functions having saddle points and local minima's) to illustrate the effectiveness of each of these techniques. **{3 points}**\n",
        "3. Show the optimization progress on mesh and contour plots. **{2+2=4 points}**\n",
        "4. Are there any limitations of these algorithms (specifically ADAM)? **{3 points}**\n",
        "5. What could be the characteristics of a better optimizer to overcome the limitations in Q4 ? **{2 points}**\n",
        "6. Design your own optimizer and compare it with ADAM. **{6+4=10 points}**\n",
        "\n",
        "---\n",
        "**Note 1:** It is alright if your optimizer cannot overperform state of the art optimizer ADAM. But you are expected to have a clear insight of each component of your proposed optimizer.\n",
        "\n",
        "**Note 2:** Clearly cite the refrenced material.\n",
        "<!-- But you will have to do a comparative analysis of the proposed optimizer and ADAM. -->\n",
        "\n",
        "---\n",
        "References:\n",
        "1. Tieleman, Tijmen and Hinton, Geoffrey (2012). Lecture 6.5-rmsprop: Divide\n",
        "the gradient by a running average of its recent magnitude. COURSERA:\n",
        "Neural Networks for Machine Learning.\n",
        "2. Nesterov, Y. (1983). A method for unconstrained convex minimization\n",
        "problem with the rate of convergence o(1/k2). Doklady ANSSSR (translated\n",
        "as Soviet.Math.Docl.), vol. 269, pp. 543– 547\n",
        "2121–2159.\n",
        "3. Kingma, D. P., & Ba, J. L. (2015). Adam: a Method for Stochastic\n",
        "Optimization. International Conference on Learning Representations, 1–13\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHUrhQ2ysfsw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all optimizers exercises to come here after\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9EZ-IVysmON",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Networks (Total for this subsection : **30 points**)\n",
        "\n",
        "---\n",
        "In this section we will work with dog breeds classification. The dataset can be downloaded from Kaggle at (https://www.kaggle.com/samcrochet/p29crosspuredogs). There are 15 breeds of dogs in this dataset. Train, Validation and Test split as provided in the dataset can be used.\n",
        "\n",
        "## To do\n",
        "\n",
        "---\n",
        "1. Download the pretrained model (VGG, ResNet, DenseNet, etc.) from the Keras or TorchVision library. {**1 point**}\n",
        "2. Modify the final fully connected layer to accomodate 15 classes. {**1 point**}\n",
        "3. Finetune the model to classify the given dataset of 15 dog breeds. {**10 points**}\n",
        "4. Use the validation set to get the optimal hyperparameters so as to achieve high validation accuracy. In case you are adopting any other strategies like Data Augmentation to increase the accuracy, kindly mention the same in the jupyter notebook. {**5 points**}\n",
        "5. Now use the test set to assess the generalization ability of the fine tuned model. Report the accuracy of the trained CNN on the test set. {**1 Point**}\n",
        "6. You may refer to the Research Paper by Selvaraju et al.[5] for a technique to explain the working of a CNN by visualizing the region of the image that the CNN is looking at, in order to make the prediction.\n",
        "7. Implement the Grad-CAM methodolgy by Selvaraju et al.[5] to visualize which regions of the test image is seminal to the classifier's output. {**10 points**}\n",
        "8. In Selvaraju et al.[5], a methodology to verify the correctness of the explanations leveraging the ground truth bounding boxes has been proposed. In a dataset as we used in this lab, where such annotations are not available, Can you think of a way to verify the correctness of the explanation generated? (Implementation not needed. Just discuss the methodology you think is suitable to verify the correctness of the generated explanations.) {**2 points**}\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "**Reference:**\n",
        "\n",
        "[5]. Ramprasaath R. Selvaraju, Michael Cogswell, Abhishek Das, Ramakrishna\n",
        "Vedantam, Devi Parikh, Dhruv Batra; Grad-CAM: Visual Explanations From\n",
        "Deep Networks via Gradient-Based Localization, The IEEE International\n",
        "Conference on Computer Vision (ICCV), 2017, pp. 618-626."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QsD0CaPm1n3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all CNN exercises to come here after\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}